{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d467ad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "from functions import *\n",
    "from constants import *\n",
    "# Active l'extension autoreload dans un notebook Jupyter\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b55ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_with_timestamp(message):\n",
    "    now = dt.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"{now} - {message}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1418364a",
   "metadata": {},
   "source": [
    "# Launching Driver and Website Main Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fe702f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = create_driver()\n",
    "driver.get(website_url)\n",
    "destroy_intrusive_elements(driver)\n",
    "wait = WebDriverWait(driver, timeout=3)\n",
    "mi_cuenta = wait.until(EC.presence_of_element_located((By.XPATH, \"//span[normalize-space()='Mi cuenta']\")))  # Remplacer par l'√©l√©ment attendu\n",
    "mi_cuenta.click()\n",
    "# Envoie de l'email sur le site\n",
    "try:\n",
    "    ingresar_email_zone = wait.until(EC.presence_of_element_located((By.XPATH, \"//input[@placeholder='Ingresa tu email']\")))\n",
    "    ingresar_email_zone.clear()\n",
    "    ingresar_email_zone.send_keys(EMAIL)\n",
    "    ingresar_email_zone.send_keys(Keys.ENTER)\n",
    "except:\n",
    "    print('NO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7edf229",
   "metadata": {},
   "source": [
    "Waiting Function statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74198653",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait10 = WebDriverWait(driver, timeout=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9d2e5c",
   "metadata": {},
   "source": [
    "# Search Mechanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b5d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_QUERY = \"portatil ASUS 1TB RTX RYZEN\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a083b0",
   "metadata": {},
   "source": [
    "Dynamically Building the Name of the CSV File to store collected Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b9a496a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Exito_Search_portatil_ASUS_1TB_RTX_RYZEN.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_output_name = f\"Exito_Search_{SEARCH_QUERY.replace(\" \", \"_\")}.csv\"\n",
    "csv_output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b377b266",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_results = {}\n",
    "today = dt.now()\n",
    "dict_results[\"Timestamp\"] = today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d66a824a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page completely loaded!\n",
      "Search field found and is clickable!\n",
      "Field cleared using JavaScript!\n",
      "No text to clear with BACKSPACE.\n",
      "Search query 'portatil ASUS 1TB RTX RYZEN' sent!\n"
     ]
    }
   ],
   "source": [
    "driver.get(website_url)\n",
    "\n",
    "try:\n",
    "    # Attendre que la page soit compl√®tement charg√©e\n",
    "    wait10.until(lambda driver: driver.execute_script(\"return document.readyState\") == \"complete\")\n",
    "    print(\"Page completely loaded!\")\n",
    "\n",
    "    # Try to find the search field\n",
    "    try:\n",
    "        search_field = wait10.until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (By.XPATH, \"//input[@data-fs-input='true' and @aria-label='search']\")\n",
    "            )\n",
    "        )\n",
    "        print(\"Search field found and is clickable!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error while finding search field: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Ensure the field is clear (use JavaScript to clear if necessary)\n",
    "        driver.execute_script(\"arguments[0].value = '';\", search_field)\n",
    "        print(\"Field cleared using JavaScript!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error while clearing field using JavaScript: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Optionally, use BACKSPACE to ensure the field is emptied\n",
    "        current_value = search_field.get_attribute('value')\n",
    "        if current_value:\n",
    "            search_field.send_keys(Keys.BACKSPACE * len(current_value))\n",
    "            print(\"Text cleared using BACKSPACE.\")\n",
    "        else:\n",
    "            print(\"No text to clear with BACKSPACE.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error while using BACKSPACE to clear text: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Send the search query\n",
    "        search_field.send_keys(SEARCH_QUERY)\n",
    "        search_field.send_keys(Keys.ENTER)\n",
    "        print(f\"Search query '{SEARCH_QUERY}' sent!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error while sending search query: {e}\")\n",
    "        raise\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"General error during search process: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eead531",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "page_num = 1\n",
    "\n",
    "while True:\n",
    "    ######################## GET PAGE ##########################################################################################################################################################################################\n",
    "    wait10.until(lambda driver: driver.execute_script(\"return document.readyState\") == \"complete\")\n",
    "    print(\"Page completely loaded!\")\n",
    "    time_sleep(page=page_num, action=\"navigate\", page_type=\"listing\")\n",
    "    print(f\"üöÄ Navigating to product listing page (Page {page_num})...\")\n",
    "\n",
    "    try:\n",
    "        product_listing = wait10.until(EC.presence_of_element_located((By.XPATH, \"//ul[contains(@data-fs-product-grid, 'true')]\")))\n",
    "        cards = product_listing.find_elements(By.XPATH, \".//div[contains(@class, 'productCard_contentInfo')]\")\n",
    "        total_results_str = wait10.until(EC.presence_of_element_located((By.XPATH, \"//p[contains(@data-testid, 'total-product-count')]\"))).text\n",
    "        match = re.search(r\"\\d{1,9}\", total_results_str)\n",
    "\n",
    "        if match:\n",
    "            total_results = int(match.group())\n",
    "            dict_results[\"Total Result\"] = total_results\n",
    "            print(f\"üî¢ Total products found: {total_results}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error while fetching the product listing: {e}\")\n",
    "        break\n",
    "\n",
    "    ######################## LOOP ON CARDS ##########################################################################################################################################################################################\n",
    "\n",
    "    for index in range(len(cards)):\n",
    "        count += 1\n",
    "        datas = {}\n",
    "\n",
    "        try:\n",
    "            # Recharger les cartes pour √©viter stale\n",
    "            product_listing = wait10.until(EC.presence_of_element_located((By.XPATH, \"//ul[contains(@data-fs-product-grid, 'true')]\")))\n",
    "            cards = product_listing.find_elements(By.XPATH, \".//div[contains(@class, 'productCard_contentInfo')]\")\n",
    "            card = cards[index]\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error refreshing card {index}: {e}\")\n",
    "            break\n",
    "\n",
    "        ######################## GET TITLE & PRICE ##########################################################################################################################################################################################\n",
    "\n",
    "        try:\n",
    "            time_sleep(page=page_num, action=\"scroll\", page_type=\"listing\")\n",
    "            print(\"üìù Scraping product title...\")\n",
    "            title = wait10.until(EC.presence_of_element_located((By.XPATH, \"//h3[contains(@class, 'styles_name__qQJiK')]\")))\n",
    "            datas[\"Title\"] = title.text\n",
    "            print(f\"üì¶ Product Title: {title.text}\")\n",
    "\n",
    "            actual_price = card.find_element(By.XPATH, \".//p[contains(@class, 'ProductPrice')]\").text\n",
    "            datas[\"Price\"] = actual_price\n",
    "            print(f\"üí∞ Current Price: {actual_price}\")\n",
    "\n",
    "            ######################## GET DISCOUNT ##########################################################################################################################################################################################\n",
    "\n",
    "            try:\n",
    "                last_price = card.find_element(By.XPATH, \".//p[contains(@class, 'promotion_price')]\").text\n",
    "                datas[\"Last Price\"] = last_price\n",
    "                print(f\"üí∏ Last Price: {last_price}\")\n",
    "                cleaned_actual_price = actual_price.replace('$', '').replace(',', '').strip()\n",
    "                cleaned_last_price = last_price.replace('$', '').replace(',', '').strip()\n",
    "                discount_value = get_discount_percentage(cleaned_last_price, cleaned_actual_price)\n",
    "                datas[\"Discount\"] = discount_value\n",
    "                print(f\"üîª Discount: {discount_value}%\")\n",
    "            except NoSuchElementException:\n",
    "                print(\"‚ùå No promotion available for this product.\")\n",
    "\n",
    "            ######################## GET IMAGES ##########################################################################################################################################################################################\n",
    "\n",
    "            try:\n",
    "                images_zone = wait10.until(EC.presence_of_element_located((By.XPATH, \".//img[contains(@alt, 'Imagen del producto')]\")))\n",
    "                img_url = images_zone.get_attribute('src')\n",
    "                datas[\"Original Image\"] = img_url\n",
    "                print(f\"üñºÔ∏è Original Image URL: {img_url}\")\n",
    "                ActionChains(driver).move_to_element(images_zone).perform()\n",
    "                new_img_url = images_zone.get_attribute('src')\n",
    "                if new_img_url != img_url:\n",
    "                    datas[\"Hovered Image\"] = new_img_url\n",
    "                    print(f\"üîÑ Hovered Image URL: {new_img_url}\")\n",
    "                else:\n",
    "                    print(\"üñºÔ∏è No change in image after hover.\")\n",
    "            except NoSuchElementException:\n",
    "                print(\"‚ùå Image not found.\")\n",
    "\n",
    "            ######################## PRODUCT DETAIL PAGE ##########################################################################################################################################################################################\n",
    "\n",
    "            print(\"üîó Navigating to product detail page...\")\n",
    "            link_producto_detalles = find_element(card, \"xpath\", \".//a[contains(@data-testid,'product-link')]\").get_attribute('href')\n",
    "            time_sleep(page=page_num, action=\"click\", page_type=\"listing\")\n",
    "            driver.get(link_producto_detalles)\n",
    "            time_sleep(page=page_num, action=\"navigate\", page_type=\"product\")\n",
    "            product_section = wait10.until(EC.presence_of_element_located((By.XPATH, \"//section[contains(@class, 'section product-details')]\")))\n",
    "\n",
    "            ######################## PLU ID ##########################################################################################################################################################################################\n",
    "\n",
    "            PLU_ID = find_element(product_section, \"xpath\", \".//span[contains(@class, 'product-title__specification')]\").text\n",
    "            datas[\"PLU_ID\"] = PLU_ID\n",
    "            print(f\"üÜî PLU ID: {PLU_ID}\")\n",
    "\n",
    "            ######################## FULL IMAGES ##########################################################################################################################################################################################\n",
    "\n",
    "            imgs_tags = find_elements(product_section, \"xpath\", \".//img[contains(@src, '')]\")\n",
    "            imgs_url = [img.get_attribute('src') for img in imgs_tags]\n",
    "            imgs_url = filter_products_img_urls(imgs_url)\n",
    "            datas['Images URL'] = imgs_url\n",
    "            print(f\"üñºÔ∏è Product Images: {imgs_url}\")\n",
    "\n",
    "            ######################## STOCK ##########################################################################################################################################################################################\n",
    "\n",
    "            stock_details = find_element(product_section, \"xpath\", \".//p[@data-fs-product-details-stock__qty='true']\").text\n",
    "            datas[\"Stock Details\"] = stock_details\n",
    "            print(f\"üì¶ Stock Status: {stock_details}\")\n",
    "\n",
    "            ######################## DEALER ##########################################################################################################################################################################################\n",
    "\n",
    "            dealer_part = find_element(product_section, \"xpath\", \".//a[contains(@href, 'seller')]\")\n",
    "            dealer = dealer_part.text\n",
    "            datas[\"Dealer\"] = dealer\n",
    "            dealer_url = dealer_part.get_attribute(\"href\")\n",
    "            datas[\"Dealer URL\"] = dealer_url\n",
    "            print(f\"üè¢ Dealer: {dealer}, URL: {dealer_url}\")\n",
    "\n",
    "            ######################## PRODUCT SPECIFICATIONS ##########################################################################################################################################################################################\n",
    "\n",
    "            try:\n",
    "                article_text_container = find_element(product_section, \"xpath\", \".//article[contains(@data-accordion-item, 'true') and contains(@data-testid, 'store-accordion-item-item')]\")\n",
    "                product_specifications = find_element(article_text_container, \"xpath\", \".//div[contains(@data-fs-content-specification,'true')]\")\n",
    "                detalles = find_elements(product_specifications, \"xpath\", \".//div[contains(@data-fs-specification,'')]\")\n",
    "                \n",
    "                for div in detalles:\n",
    "                    try:\n",
    "                        paragraph_title = find_element(div, \"xpath\", \".//p[contains(@data-fs-title-specification, 'true')]\").text\n",
    "                        paragraph_text = find_element(div, \"xpath\", \".//p[contains(@data-fs-text-specification, 'true')]\").text\n",
    "                        detail = f\"{paragraph_title}: {paragraph_text}\"\n",
    "                        print(f\"üìã Product Specification: {detail}\")\n",
    "                    except (NoSuchElementException, TimeoutException):\n",
    "                        pass\n",
    "            except (NoSuchElementException, TimeoutException):\n",
    "                print(\"üîç Could not find the main product specification section.\")\n",
    "\n",
    "\n",
    "            ######################## PRODUCT DESCRIPTION ##########################################################################################################################################################################################\n",
    "\n",
    "            product_description = find_element(article_text_container, \"xpath\", \".//div[contains(@data-fs-description-text, '')]\").text\n",
    "            datas[\"Product Description\"] = product_description\n",
    "            print(f\"üìù Product Description: {product_description}\")\n",
    "\n",
    "            ######################## DELIVERY DETAILS ##########################################################################################################################################################################################\n",
    "\n",
    "            delivery_details_zone = find_element(product_section, \"xpath\", \".//section[contains(@class, 'deliveryPromises')]\")\n",
    "            delivery_details = find_element(delivery_details_zone, \"xpath\", \".//span[contains(@data-fs-promises-bold,'true')]\").text\n",
    "            disponibilidad_compra_y_recoge = find_element(delivery_details_zone, \"xpath\", \".//p[contains(@data-fs-promises-bold,'true')]\").text\n",
    "            datas[\"Delivery Details\"] = delivery_details\n",
    "            datas[\"Purchase & Pick-up\"] = disponibilidad_compra_y_recoge\n",
    "            print(f\"üöö Delivery Info: {delivery_details}\")\n",
    "            print(f\"üè™ Availability for Pick-up: {disponibilidad_compra_y_recoge}\")\n",
    "\n",
    "            ######################## SAVE & GO BACK ##########################################################################################################################################################################################\n",
    "\n",
    "            dict_results[count] = datas\n",
    "\n",
    "            driver.back()\n",
    "            time_sleep(page=page_num, action=\"navigate\", page_type=\"listing\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error occurred while scraping product: {e}\")\n",
    "            break\n",
    "\n",
    "    ######################## NEXT PAGE ##########################################################################################################################################################################################\n",
    "\n",
    "    try:\n",
    "        time_sleep(page=page_num, action=\"click\", page_type=\"listing\")\n",
    "        button_next_page = wait10.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'Pagination_next')]\")))\n",
    "        button_next_page.click()\n",
    "        page_num += 1\n",
    "        print(f\"üìÑ Moving to page {page_num}...\")\n",
    "    except NoSuchElementException:\n",
    "        print(\"üö´ No next page found. Stopping the loop...\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6904168",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8e370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "page_num = 1\n",
    "\n",
    "######## LOOP ON PAGES #############################################################################################################################################################\n",
    "\n",
    "while True:\n",
    "\n",
    "    ######## GO TO LISTING PAGE #############################################################################################################################################################\n",
    "\n",
    "    time_sleep(page=page_num, action=\"navigate\", page_type=\"listing\")\n",
    "    print(f\"üöÄ Navigating to product listing page (Page {page_num})...\")\n",
    "\n",
    "    try:\n",
    "        product_listing = wait10.until(EC.presence_of_element_located((By.XPATH, \"//ul[contains(@data-fs-product-grid, 'true')]\")))\n",
    "        cards = product_listing.find_elements(By.XPATH, \".//div[contains(@class, 'productCard_contentInfo')]\")\n",
    "\n",
    "        total_results_str = wait10.until(EC.presence_of_element_located((By.XPATH, \"//p[contains(@data-testid, 'total-product-count')]\"))).text\n",
    "        match = re.search(r\"\\d{1,9}\", total_results_str)\n",
    "\n",
    "        if match:\n",
    "            total_results = int(match.group())\n",
    "            dict_results[\"Total Result\"] = total_results\n",
    "            print(f\"üî¢ Total products found: {total_results}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error while fetching the product listing: {e}\")\n",
    "        break\n",
    "\n",
    "    ######## LOOP ON CARDS #############################################################################################################################################################\n",
    "\n",
    "    for index in range(len(cards)):\n",
    "        try:\n",
    "            ######## REFRESH CARD #############################################################################################################################################################\n",
    "\n",
    "            product_listing = wait10.until(EC.presence_of_element_located((By.XPATH, \"//ul[contains(@data-fs-product-grid, 'true')]\")))\n",
    "            cards = product_listing.find_elements(By.XPATH, \".//div[contains(@class, 'productCard_contentInfo')]\")\n",
    "            card = cards[index]\n",
    "\n",
    "            count += 1\n",
    "            datas = {}\n",
    "\n",
    "            ######## TITLE #############################################################################################################################################################\n",
    "\n",
    "            time_sleep(page=page_num, action=\"scroll\", page_type=\"listing\")\n",
    "            print(\"üìù Scraping product title...\")\n",
    "\n",
    "            title = wait10.until(EC.presence_of_element_located((By.XPATH, \"//h3[contains(@class, 'styles_name__qQJiK')]\")))\n",
    "            datas[\"Title\"] = title.text\n",
    "            print(f\"üì¶ Product Title: {title.text}\")\n",
    "\n",
    "            ######## PRICE #############################################################################################################################################################\n",
    "\n",
    "            actual_price = card.find_element(By.XPATH, \".//p[contains(@class, 'ProductPrice')]\").text\n",
    "            datas[\"Price\"] = actual_price\n",
    "            print(f\"üí∞ Current Price: {actual_price}\")\n",
    "\n",
    "            try:\n",
    "                last_price = card.find_element(By.XPATH, \".//p[contains(@class, 'promotion_price')]\").text\n",
    "                datas[\"Last Price\"] = last_price\n",
    "                print(f\"üí∏ Last Price: {last_price}\")\n",
    "\n",
    "                cleaned_actual_price = actual_price.replace('$', '').replace(',', '').strip()\n",
    "                cleaned_last_price = last_price.replace('$', '').replace(',', '').strip()\n",
    "                discount_value = get_discount_percentage(cleaned_last_price, cleaned_actual_price)\n",
    "                datas[\"Discount\"] = discount_value\n",
    "                print(f\"üîª Discount: {discount_value}%\")\n",
    "            except NoSuchElementException:\n",
    "                print(\"‚ùå No promotion available for this product.\")\n",
    "\n",
    "            ######## IMAGES #############################################################################################################################################################\n",
    "\n",
    "            try:\n",
    "                images_zone = wait10.until(EC.presence_of_element_located((By.XPATH, \".//img[contains(@alt, 'Imagen del producto')]\")))\n",
    "                img_url = images_zone.get_attribute('src')\n",
    "                datas[\"Original Image\"] = img_url\n",
    "                print(f\"üñºÔ∏è Original Image URL: {img_url}\")\n",
    "\n",
    "                ActionChains(driver).move_to_element(images_zone).perform()\n",
    "                new_img_url = images_zone.get_attribute('src')\n",
    "\n",
    "                if new_img_url != img_url:\n",
    "                    datas[\"Hovered Image\"] = new_img_url\n",
    "                    print(f\"üîÑ Hovered Image URL: {new_img_url}\")\n",
    "                else:\n",
    "                    print(\"üñºÔ∏è No change in image after hover.\")\n",
    "\n",
    "            except NoSuchElementException:\n",
    "                print(\"‚ùå Image not found.\")\n",
    "\n",
    "            ######## PRODUCT DETAIL PAGE #############################################################################################################################################################\n",
    "\n",
    "            print(\"üîó Navigating to product detail page...\")\n",
    "            link_producto_detalles = find_element(card, \"xpath\", \".//a[contains(@data-testid,'product-link')]\").get_attribute('href')\n",
    "            time_sleep(page=page_num, action=\"click\", page_type=\"listing\")\n",
    "            driver.get(link_producto_detalles)\n",
    "            time_sleep(page=page_num, action=\"navigate\", page_type=\"product\")\n",
    "\n",
    "            product_section = wait10.until(EC.presence_of_element_located((By.XPATH, \"//section[contains(@class, 'section product-details')]\")))\n",
    "\n",
    "            ######## PLU ID #############################################################################################################################################################\n",
    "\n",
    "            PLU_ID = find_element(product_section, \"xpath\", \".//span[contains(@class, 'product-title__specification')]\").text\n",
    "            datas[\"PLU_ID\"] = PLU_ID\n",
    "            print(f\"üÜî PLU ID: {PLU_ID}\")\n",
    "\n",
    "            ######## PRODUCT IMAGES #############################################################################################################################################################\n",
    "\n",
    "            imgs_tags = find_elements(product_section, \"xpath\", \".//img[contains(@src, '')]\")\n",
    "            imgs_url = [img.get_attribute('src') for img in imgs_tags]\n",
    "            imgs_url = filter_products_img_urls(imgs_url)\n",
    "            datas['Images URL'] = imgs_url\n",
    "            print(f\"üñºÔ∏è Product Images: {imgs_url}\")\n",
    "\n",
    "            ######## STOCK #############################################################################################################################################################\n",
    "\n",
    "            stock_details = find_element(product_section, \"xpath\", \".//p[@data-fs-product-details-stock__qty='true']\").text\n",
    "            datas[\"Stock Details\"] = stock_details\n",
    "            print(f\"üì¶ Stock Status: {stock_details}\")\n",
    "\n",
    "            ######## DEALER #############################################################################################################################################################\n",
    "\n",
    "            dealer_part = find_element(product_section, \"xpath\", \".//a[contains(@href, 'seller')]\")\n",
    "            dealer = dealer_part.text\n",
    "            datas[\"Dealer\"] = dealer\n",
    "            dealer_url = dealer_part.get_attribute(\"href\")\n",
    "            datas[\"Dealer URL\"] = dealer_url\n",
    "            print(f\"üè¢ Dealer: {dealer}, URL: {dealer_url}\")\n",
    "\n",
    "            ######## PRODUCT SPECIFICATIONS #############################################################################################################################################################\n",
    "\n",
    "            article_text_container = find_element(product_section, \"xpath\", \".//article[contains(@data-accordion-item, 'true') and contains(@data-testid, 'store-accordion-item-item')]\")\n",
    "            product_specifications = find_element(article_text_container, \"xpath\", \".//div[contains(@data-fs-content-specification,'true')]\")\n",
    "            detalles = find_elements(product_specifications, \"xpath\", \".//div[contains(@data-fs-specification,'')]\")\n",
    "\n",
    "            for div in detalles:\n",
    "                paragraph_title = find_element(div, \"xpath\", \".//p[contains(@data-fs-title-specification, 'true')]\").text\n",
    "                paragraph_text = find_element(div, \"xpath\", \".//p[contains(@data-fs-text-specification, 'true')]\").text\n",
    "                detail = f\"{paragraph_title}: {paragraph_text}\"\n",
    "                print(f\"üìã Product Specification: {detail}\")\n",
    "\n",
    "            ######## PRODUCT DESCRIPTION #############################################################################################################################################################\n",
    "\n",
    "            product_description = find_element(article_text_container, \"xpath\", \".//div[contains(@data-fs-description-text, '')]\").text\n",
    "            datas[\"Product Description\"] = product_description\n",
    "            print(f\"üìù Product Description: {product_description}\")\n",
    "\n",
    "            ######## DELIVERY #############################################################################################################################################################\n",
    "\n",
    "            delivery_details_zone = find_element(product_section, \"xpath\", \".//section[contains(@class, 'deliveryPromises')]\")\n",
    "            delivery_details = find_element(delivery_details_zone, \"xpath\", \".//span[contains(@data-fs-promises-bold,'true')]\").text\n",
    "            disponibilidad_compra_y_recoge = find_element(delivery_details_zone, \"xpath\", \".//p[contains(@data-fs-promises-bold,'true')]\").text\n",
    "            datas[\"Delivery Details\"] = delivery_details\n",
    "            datas[\"Purchase & Pick-up\"] = disponibilidad_compra_y_recoge\n",
    "            print(f\"üöö Delivery Info: {delivery_details}\")\n",
    "            print(f\"üè™ Availability for Pick-up: {disponibilidad_compra_y_recoge}\")\n",
    "\n",
    "            ######## STORE RESULTS #############################################################################################################################################################\n",
    "\n",
    "            dict_results[count] = datas\n",
    "\n",
    "            ######## BACK TO LISTING #############################################################################################################################################################\n",
    "\n",
    "            driver.back()\n",
    "            time_sleep(page=page_num, action=\"navigate\", page_type=\"listing\")\n",
    "            wait10.until(EC.presence_of_element_located((By.XPATH, \"//ul[contains(@data-fs-product-grid, 'true')]\")))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error occurred while scraping product: {e}\")\n",
    "            break\n",
    "\n",
    "    ######## NEXT PAGE #############################################################################################################################################################\n",
    "\n",
    "    try:\n",
    "        time_sleep(page=page_num, action=\"click\", page_type=\"listing\")\n",
    "        button_next_page = wait10.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'Pagination_next')]\")))\n",
    "        button_next_page.click()\n",
    "        page_num += 1\n",
    "        print(f\"üìÑ Moving to page {page_num}...\")\n",
    "    except NoSuchElementException:\n",
    "        print(\"üö´ No next page found. Stopping the loop...\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddae67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_results_str = wait10.until(EC.presence_of_element_located((By.XPATH, \"//p[contains(@data-testid, 'total-product-count')]\"))).text\n",
    "match = re.search(r\"\\d{1,9}\", total_results_str)\n",
    "\n",
    "if match:\n",
    "    total_results = int(match.group())\n",
    "    print(f\"Total Result : {total_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad63302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.exito.com/s?q=portatil+ASUS+Ryzen+7+1TB+RAM&sort=score_desc&page=0\")\n",
    "\n",
    "product_listing = wait10.until(EC.presence_of_element_located((By.XPATH, \"//ul[contains(@data-fs-product-grid, 'true')]\")))\n",
    "cards = product_listing.find_elements(By.XPATH, \".//div[contains(@class, 'productCard_contentInfo')]\")\n",
    "\n",
    "one_card = cards[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9080ba6b",
   "metadata": {},
   "source": [
    "# Article Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311f258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ PRODUCT PAGE SCRAPING ###############################################################################################################################################\n",
    "##################################################################################################################################################################################################\n",
    "\n",
    "time_sleep(page=page_num, action=\"navigate\", page_type=\"product\")\n",
    "product_section = wait10.until(EC.presence_of_element_located((By.XPATH, \"//section[contains(@class, 'section product-details')]\")))\n",
    "\n",
    "######################### GETTING PRODUCT ID ###############################################################################################################################################\n",
    "\n",
    "PLU_ID = find_element(product_section, \"xpath\", \".//span[contains(@class, 'product-title__specification')]\").text\n",
    "datas[\"PLU_ID\"] = PLU_ID\n",
    "print(f\"üÜî PLU ID: {PLU_ID}\")\n",
    "\n",
    "######################### GET PRODUCT IMAGES ###############################################################################################################################################\n",
    "\n",
    "imgs_tags = find_elements(product_section, \"xpath\", \".//img[contains(@src, '')]\")\n",
    "imgs_url = [img.get_attribute('src') for img in imgs_tags]\n",
    "imgs_url = filter_products_img_urls(imgs_url)\n",
    "datas['Images URL'] = imgs_url\n",
    "print(f\"üñºÔ∏è Product Images: {imgs_url}\")\n",
    "\n",
    "######################### GETTING STOCK DETAILS ###############################################################################################################################################\n",
    "\n",
    "stock_details = find_element(product_section, \"xpath\", \".//p[@data-fs-product-details-stock__qty='true']\").text\n",
    "datas[\"Stock Details\"] = stock_details\n",
    "print(f\"üì¶ Stock Status: {stock_details}\")\n",
    "\n",
    "######################### GETTING DEALER DETAILS ###############################################################################################################################################\n",
    "\n",
    "dealer = find_element(product_section, \"xpath\", \".//a[contains(@href, 'seller')]\").text\n",
    "\n",
    "datas[\"Dealer\"] = dealer\n",
    "dealer_url = dealer_part.get_attribute(\"href\")\n",
    "datas[\"Dealer URL\"] = dealer_url\n",
    "print(f\"üè¢ Dealer: {dealer}, URL: {dealer_url}\")\n",
    "\n",
    "######################### GETTING PRODUCT SPECIFICATIONS ###############################################################################################################################################\n",
    "\n",
    "article_text_container = find_element(product_section, \"xpath\", \".//article[contains(@data-accordion-item, 'true') and contains(@data-testid, 'store-accordion-item-item')]\")\n",
    "product_specifications = find_element(article_text_container, \"xpath\", \".//div[contains(@data-fs-content-specification,'true')]\")\n",
    "detalles = find_elements(product_specifications, \"xpath\", \".//div[contains(@data-fs-specification,'')]\")\n",
    "for div in detalles:\n",
    "    paragraph_title = find_element(div, \"xpath\", \".//p[contains(@data-fs-title-specification, 'true')]\").text\n",
    "    paragraph_text = find_element(div, \"xpath\", \".//p[contains(@data-fs-text-specification, 'true')]\").text\n",
    "    detail = f\"{paragraph_title}: {paragraph_text}\"\n",
    "    print(f\"üìã Product Specification: {detail}\")\n",
    "\n",
    "######################### GETTING PRODUCT DESCRIPTION ###############################################################################################################################################\n",
    "\n",
    "product_description = find_element(article_text_container, \"xpath\", \".//div[contains(@data-fs-description-text, '')]\").text\n",
    "datas[\"Product Description\"] = product_description\n",
    "print(f\"üìù Product Description: {product_description}\")\n",
    "\n",
    "delivery_details_zone = find_element(product_section, \"xpath\", \".//section[contains(@class, 'deliveryPromises')]\")\n",
    "delivery_details = find_element(delivery_details_zone, \"xpath\", \".//span[contains(@data-fs-promises-bold,'true')]\").text\n",
    "disponibilidad_compra_y_recoge = find_element(delivery_details_zone, \"xpath\", \".//p[contains(@data-fs-promises-bold,'true')]\").text\n",
    "datas[\"Delivery Details\"] = delivery_details\n",
    "datas[\"Purchase & Pick-up\"] = disponibilidad_compra_y_recoge\n",
    "print(f\"üöö Delivery Info: {delivery_details}\")\n",
    "print(f\"üè™ Availability for Pick-up: {disponibilidad_compra_y_recoge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########  PRODUCT PAGE SCRAPING ###########################################################################################################################################################################################################################\n",
    "\n",
    "product_section = find_element(driver, \"xpath\", \"//section[contains(@class, 'section product-details')]\")\n",
    "\n",
    "PLU_ID = find_element(product_section, \"xpath\", \".//span[contains(@class, 'product-title__specification')]\").text\n",
    "\n",
    "# R√©cup√©ration des images\n",
    "imgs_tags = find_elements(product_section, \"xpath\", \".//img[contains(@src, '')]\")\n",
    "\n",
    "imgs_url = [img.get_attribute('src') for img in imgs_tags]\n",
    "\n",
    "imgs_url =filter_products_img_urls(imgs_url)\n",
    "print(imgs_url)\n",
    "\n",
    "stock_details = find_element(product_section, \"xpath\", \".//p[@data-fs-product-details-stock__qty='true']\").text\n",
    "\n",
    "# Affiche le texte\n",
    "print(f\"Texte complet : {stock_details}\")\n",
    "\n",
    "\n",
    "# Trouver l'√©l√©ment <a> contenant \"Mundo digital vm\"\n",
    "dealer_part = find_element(product_section, \"xpath\", \".//a[contains(text(), '')]\")\n",
    "\n",
    "# R√©cup√©rer le texte de l'√©l√©ment <a> (le texte \"Mundo digital vm\")\n",
    "dealer = dealer_part.text\n",
    "print(f\"Dealer: {dealer}\")\n",
    "\n",
    "# R√©cup√©rer l'URL associ√©e √† cet √©l√©ment <a>\n",
    "dealer_url = dealer_part.get_attribute(\"href\")\n",
    "print(f\"Dealer URL : {dealer_url}\")\n",
    "\n",
    "\n",
    "article_text_container = find_element(product_section, \n",
    "    \"xpath\", \".//article[contains(@data-accordion-item, 'true') and contains(@data-testid, 'store-accordion-item-item')]\")\n",
    "\n",
    "product_specifications = find_element(article_text_container, \n",
    "            \"xpath\", \".//div[contains(@data-fs-content-specification,'true')]\")\n",
    "detalles = find_elements(product_specifications, \n",
    "        \"xpath\", \".//div[contains(@data-fs-specification,'')]\")\n",
    "len(detalles)\n",
    "for div in detalles:\n",
    "    paragraph_title = find_element(div, \"xpath\", \".//p[contains(@data-fs-title-specification, 'true')]\").text\n",
    "    paragraph_text = find_element(div, \"xpath\", \".//p[contains(@data-fs-text-specification, 'true')]\").text\n",
    "    detail = f\"{paragraph_title}: {paragraph_text}\"\n",
    "    print(detail)\n",
    "product_description = find_element(article_text_container, \"xpath\", \n",
    "                    \".//div[contains(@data-fs-description-text, '')]\").text\n",
    "\n",
    "normalized_description = normalize_text(product_description)\n",
    "print(normalized_description)\n",
    "\n",
    "delivery_details_zone = find_element(product_section, \"xpath\", \n",
    "\".//section[contains(@class, 'deliveryPromises')]\")\n",
    "delivery_details = find_element(delivery_details_zone, \"xpath\",\n",
    "            \".//span[contains(@data-fs-promises-bold,'true')]\").text\n",
    "disponibilidad_compra_y_recoge = find_element(delivery_details_zone, \"xpath\",\n",
    "            \".//p[contains(@data-fs-promises-bold,'true')]\").text\n",
    "\n",
    "##########  ###########################################################################################################################################################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c248a",
   "metadata": {},
   "source": [
    "Go on the Computer Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca4983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"Tecnolog√≠a\"\n",
    "article_type_choice = \"Port√°tiles\"\n",
    "\n",
    "main_page=driver.current_url\n",
    "def go_to_article_page(driver, category, article_type):\n",
    "    import time\n",
    "    from selenium.webdriver.common.by import By\n",
    "\n",
    "    try:\n",
    "        # R√©cup√®re le menu des cat√©gories\n",
    "        categories_menu = driver.find_element(By.XPATH, '//*[@id=\"header-page\"]/aside/ul/section[2]')\n",
    "\n",
    "        # Cherche tous les div ayant l'attribut data-link-content=\"true\"\n",
    "        divs_with_data_link_content = categories_menu.find_elements(By.XPATH, './/div[@data-link-content=\"true\"]')\n",
    "\n",
    "        # Clique sur la cat√©gorie principale\n",
    "        for div in divs_with_data_link_content:\n",
    "            if div.text.strip() == category:\n",
    "                div.click()\n",
    "                print(f\"Cat√©gorie '{category}' cliqu√©e.\")\n",
    "                time.sleep(1)\n",
    "                break\n",
    "\n",
    "        # Menu d√©roul√© : chercher le type d'article\n",
    "        selected_menu = driver.find_element(By.XPATH, './/ul[@data-content-list=\"true\"]')\n",
    "        list_elements = selected_menu.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "        for li in list_elements:\n",
    "            if li.text.strip() == article_type:\n",
    "                try:\n",
    "                    link = li.find_element(By.TAG_NAME, 'a')\n",
    "                    link.click()\n",
    "                    print(f\"Lien cliqu√© vers la page '{article_type}'\")\n",
    "                    time.sleep(2)\n",
    "                    return driver.current_url\n",
    "                except:\n",
    "                    print(f\"Lien introuvable dans l'√©l√©ment '{article_type}'\")\n",
    "                    return None\n",
    "        print(f\"Type d'article '{article_type}' non trouv√©.\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la navigation : {e}\")\n",
    "        return None\n",
    "try:\n",
    "    go_to_article_page(driver, category, article_type_choice)\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1458d8",
   "metadata": {},
   "source": [
    "Getting all the Checkboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdcf38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "computer_filter_menu = driver.find_element(By.XPATH, \"//div[@class='accordion_fs-accordion__mi4MR']\")\n",
    "\n",
    "# R√©cup√®re tous les titres des filtres (balises h4)\n",
    "filters = computer_filter_menu.find_elements(By.TAG_NAME, 'h4')\n",
    "Sub_categor√≠a = filters[1]\n",
    "\n",
    "# desktop-store-filter-Sub-categor√≠a-Accesorios de c√°maras\n",
    "\n",
    "# V√©rifier si l'√©l√©ment Sub_categor√≠a a √©t√© trouv√©\n",
    "if Sub_categor√≠a:\n",
    "    # Trouver toutes les checkboxes √† l'int√©rieur de 'Sub_categor√≠a'\n",
    "    checkboxes = Sub_categor√≠a.find_elements(By.XPATH, '//input[@type=\"checkbox\" and @data-fs-checkbox=\"true\"]')\n",
    "    print(f\"Nombre de checkboxes trouv√©es : {len(checkboxes)}\")\n",
    "    for checkbox in checkboxes:\n",
    "        print(checkbox.get_attribute(\"data-value\"))\n",
    "else:\n",
    "    print(\"L'√©l√©ment 'Sub-categor√≠a' n'a pas √©t√© trouv√©.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2198c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cocher_checkboxes(filters_choice, checkboxes, driver):\n",
    "    # Normalisation des filtres\n",
    "    filters_normalized = [unidecode(item.lower()) for item in filters_choice]\n",
    "\n",
    "    for i in range(len(checkboxes)):\n",
    "        try:\n",
    "            # On relocalise √† chaque boucle pour √©viter stale\n",
    "            checkboxes_refreshed = driver.find_elements(By.CSS_SELECTOR, \"input[type='checkbox'][data-value]\")\n",
    "            if i >= len(checkboxes_refreshed):\n",
    "                break  # Au cas o√π le DOM change\n",
    "\n",
    "            checkbox = checkboxes_refreshed[i]\n",
    "\n",
    "            data_value_raw = checkbox.get_attribute(\"data-value\")\n",
    "            if data_value_raw is None:\n",
    "                continue\n",
    "\n",
    "            data_value = unidecode(data_value_raw.replace(\"-\", \" \").lower())\n",
    "            matched = any(f in data_value for f in filters_normalized)\n",
    "\n",
    "            if matched and not checkbox.is_selected():\n",
    "                click_with_JS(checkbox, driver)\n",
    "                print(f\"[CHECK] Checkbox pour '{data_value}' coch√©e.\")\n",
    "\n",
    "            elif not matched and checkbox.is_selected():\n",
    "                click_with_JS(checkbox, driver)\n",
    "                print(f\"[UNCHECK] Checkbox pour '{data_value}' d√©coch√©e.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Probl√®me sur checkbox {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "from unidecode import unidecode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df878ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"asus\", \"8 gb\", \"16 GB\", \"nvidia\", \"amd\", \"24 gb\", \"32 gb\", \"ssd\",\n",
    "    \"ryzen 7\", \"500 GB\", \"1 TB\", \"i7\", \"gaming\", 'portatiles'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c26adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cocher_checkboxes(filters_choice=queries, checkboxes=checkboxes,driver=driver)\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed6ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from currencies import Currency\n",
    "\n",
    "class CurrencyConverter:\n",
    "    def __init__(self, from_currency, to_currency, exchange_rate):\n",
    "        self.from_currency = Currency(from_currency)\n",
    "        self.to_currency = Currency(to_currency)\n",
    "        self.exchange_rate = exchange_rate\n",
    "\n",
    "    def convert(self, amount):\n",
    "        # Effectuer la conversion de l'euro vers le COP\n",
    "        amount_in_target_currency = amount * self.exchange_rate\n",
    "        # Retourne un float sans formatage en cha√Æne\n",
    "        return amount_in_target_currency\n",
    "\n",
    "# Exemple d'utilisation :\n",
    "# Taux de conversion (peut √™tre r√©cup√©r√© depuis une API, ici 1 EUR = 4500 COP)\n",
    "exchange_rate_eur_to_cop = 4500\n",
    "\n",
    "# Cr√©ation d'un convertisseur de devise\n",
    "converter_eur_cop = CurrencyConverter('EUR', 'COP', exchange_rate_eur_to_cop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation\n",
    "min_value = converter_eur_cop.convert(300)  # Conversion de 300 EUR\n",
    "max_value = converter_eur_cop.convert(500)  # Conversion de 450 EUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff756298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_slider_value(driver, min_value, max_value):\n",
    "    # R√©cup√©rer la valeur actuelle des deux sliders avant de les changer\n",
    "    initial_left_value = driver.execute_script(\"\"\"\n",
    "    const leftSlider = document.querySelector('input[type=\"range\"][data-slider-thumb=\"left\"]');\n",
    "    return leftSlider ? leftSlider.value : null;\n",
    "    \"\"\")\n",
    "    \n",
    "    initial_right_value = driver.execute_script(\"\"\"\n",
    "    const rightSlider = document.querySelector('input[type=\"range\"][data-slider-thumb=\"right\"]');\n",
    "    return rightSlider ? rightSlider.value : null;\n",
    "    \"\"\")\n",
    "\n",
    "    print(f\"Valeur initiale du slider gauche : {initial_left_value}\")\n",
    "    print(f\"Valeur initiale du slider droit : {initial_right_value}\")\n",
    "\n",
    "    # Changer la valeur des sliders via JavaScript\n",
    "    script = \"\"\"\n",
    "    const leftSlider = document.querySelector('input[type=\"range\"][data-slider-thumb=\"left\"]');\n",
    "    const rightSlider = document.querySelector('input[type=\"range\"][data-slider-thumb=\"right\"]');\n",
    "    \n",
    "    if (leftSlider) {\n",
    "        leftSlider.value = arguments[0]; // D√©finir la nouvelle valeur du slider gauche\n",
    "        leftSlider.dispatchEvent(new Event('input', { bubbles: true })); // Simuler l'√©v√©nement 'input'\n",
    "        leftSlider.dispatchEvent(new Event('change', { bubbles: true })); // Simuler l'√©v√©nement 'change'\n",
    "    }\n",
    "\n",
    "    if (rightSlider) {\n",
    "        rightSlider.value = arguments[1]; // D√©finir la nouvelle valeur du slider droit\n",
    "        rightSlider.dispatchEvent(new Event('input', { bubbles: true })); // Simuler l'√©v√©nement 'input'\n",
    "        rightSlider.dispatchEvent(new Event('change', { bubbles: true })); // Simuler l'√©v√©nement 'change'\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Ex√©cuter le script pour changer les valeurs des deux sliders\n",
    "    driver.execute_script(script, min_value, max_value)\n",
    "\n",
    "    # R√©cup√©rer la nouvelle valeur des deux sliders apr√®s modification\n",
    "    final_left_value = driver.execute_script(\"\"\"\n",
    "    const leftSlider = document.querySelector('input[type=\"range\"][data-slider-thumb=\"left\"]');\n",
    "    return leftSlider ? leftSlider.value : null;\n",
    "    \"\"\")\n",
    "\n",
    "    final_right_value = driver.execute_script(\"\"\"\n",
    "    const rightSlider = document.querySelector('input[type=\"range\"][data-slider-thumb=\"right\"]');\n",
    "    return rightSlider ? rightSlider.value : null;\n",
    "    \"\"\")\n",
    "\n",
    "    print(f\"Valeur apr√®s modification du slider gauche : {final_left_value}\")\n",
    "    print(f\"Valeur apr√®s modification du slider droit : {final_right_value}\")\n",
    "\n",
    "    # Comparer les valeurs avant et apr√®s\n",
    "    if initial_left_value != final_left_value:\n",
    "        print(f\"Le slider gauche a √©t√© mis √† jour avec succ√®s. Nouvelle valeur : {final_left_value}\")\n",
    "    else:\n",
    "        print(f\"Aucune modification n'a √©t√© effectu√©e sur le slider gauche. Valeur actuelle : {final_left_value}\")\n",
    "\n",
    "    if initial_right_value != final_right_value:\n",
    "        print(f\"Le slider droit a √©t√© mis √† jour avec succ√®s. Nouvelle valeur : {final_right_value}\")\n",
    "    else:\n",
    "        print(f\"Aucune modification n'a √©t√© effectu√©e sur le slider droit. Valeur actuelle : {final_right_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975fa476",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_slider_value(driver, min_value, max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f4e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aplicar_filtros = driver.find_element(By.XPATH, \"//button[normalize-space()='Aplicar filtros']\")\n",
    "aplicar_filtros.click()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
